{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"voc_annotation","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP1+akhmYTvlNgUbLygIW6N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# # Mount to Google Drive to train on Colab\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd  /content/drive/'My Drive'/\"SP22_ML_final_project\"/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hXHs7akQNtVs","executionInfo":{"status":"ok","timestamp":1650294744285,"user_tz":240,"elapsed":839,"user":{"displayName":"Jiayao Jin","userId":"06055959675371134357"}},"outputId":"e7a35c79-c3f8-4352-d746-914466e97098"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/SP22_ML_final_project\n"]}]},{"cell_type":"code","source":["import os\n","import random\n","import xml.etree.ElementTree as ET\n","\n","from utils.utils import get_classes\n","from utils.convert_png_to_jpg import PNG_to_JPG"],"metadata":{"id":"Mdg3HLfZNo-W","executionInfo":{"status":"ok","timestamp":1650294971727,"user_tz":240,"elapsed":155,"user":{"displayName":"Jiayao Jin","userId":"06055959675371134357"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# If needed, convert PNG images to JPG images\n","# comment the code if not needed\n","from_path = \"./dataset/facemask_dataset/images\"\n","to_path = \"./VOCdevkit/VOC2007/JPEGImages\"\n","PNG_to_JPG(from_path, to_path)"],"metadata":{"id":"5shtBQINPus2","executionInfo":{"status":"ok","timestamp":1650296219604,"user_tz":240,"elapsed":197685,"user":{"displayName":"Jiayao Jin","userId":"06055959675371134357"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["print(len(os.listdir(from_path)))\n","print(len(os.listdir(to_path)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6lKNUjhkUE9I","executionInfo":{"status":"ok","timestamp":1650296219987,"user_tz":240,"elapsed":11,"user":{"displayName":"Jiayao Jin","userId":"06055959675371134357"}},"outputId":"84df5359-6ebb-4e88-af7f-dc18e8ee9c1c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["853\n","853\n"]}]},{"cell_type":"code","source":["def convert_annotation(year, image_id, list_file):\n","    in_file = open(os.path.join(VOCdevkit_path, 'VOC%s/Annotations/%s.xml' % (year, image_id)), encoding='utf-8')\n","    tree = ET.parse(in_file)\n","    root = tree.getroot()\n","\n","    for obj in root.iter('object'):\n","        difficult = 0\n","        if obj.find('difficult') != None:\n","            difficult = obj.find('difficult').text\n","        cls = obj.find('name').text\n","        if cls not in classes or int(difficult) == 1:\n","            continue\n","        cls_id = classes.index(cls)\n","        xmlbox = obj.find('bndbox')\n","        b = (int(float(xmlbox.find('xmin').text)), int(float(xmlbox.find('ymin').text)),\n","             int(float(xmlbox.find('xmax').text)), int(float(xmlbox.find('ymax').text)))\n","        list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))"],"metadata":{"id":"673c3E4kN14z","executionInfo":{"status":"ok","timestamp":1650296300226,"user_tz":240,"elapsed":145,"user":{"displayName":"Jiayao Jin","userId":"06055959675371134357"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"JF8XzDLjNbZN","executionInfo":{"status":"ok","timestamp":1650296301943,"user_tz":240,"elapsed":123,"user":{"displayName":"Jiayao Jin","userId":"06055959675371134357"}}},"outputs":[],"source":["annotation_mode = 0\n","classes_path = 'model_data/facemask_classes.txt'\n","trainval_percent = 0.9\n","train_percent = 0.9\n","VOCdevkit_path = 'VOCdevkit'\n","VOCdevkit_sets = [('2007', 'train'), ('2007', 'val')]\n","classes, _ = get_classes(classes_path)"]},{"cell_type":"code","source":["random.seed(0)\n","if annotation_mode == 0 or annotation_mode == 1:\n","    print(\"Generate txt in ImageSets.\")\n","    xmlfilepath = os.path.join(VOCdevkit_path, 'VOC2007/Annotations')\n","    saveBasePath = os.path.join(VOCdevkit_path, 'VOC2007/ImageSets/Main')\n","    temp_xml = os.listdir(xmlfilepath)\n","    total_xml = []\n","    for xml in temp_xml:\n","        if xml.endswith(\".xml\"):\n","            total_xml.append(xml)\n","\n","    num = len(total_xml)\n","    list = range(num)\n","    tv = int(num * trainval_percent)\n","    tr = int(tv * train_percent)\n","    trainval = random.sample(list, tv)\n","    train = random.sample(trainval, tr)\n","\n","    print(\"train and val size\", tv)\n","    print(\"train size\", tr)\n","    ftrainval = open(os.path.join(saveBasePath, 'trainval.txt'), 'w')\n","    ftest = open(os.path.join(saveBasePath, 'test.txt'), 'w')\n","    ftrain = open(os.path.join(saveBasePath, 'train.txt'), 'w')\n","    fval = open(os.path.join(saveBasePath, 'val.txt'), 'w')\n","\n","    for i in list:\n","        name = total_xml[i][:-4] + '\\n'\n","        if i in trainval:\n","            ftrainval.write(name)\n","            if i in train:\n","                ftrain.write(name)\n","            else:\n","                fval.write(name)\n","        else:\n","            ftest.write(name)\n","\n","    ftrainval.close()\n","    ftrain.close()\n","    fval.close()\n","    ftest.close()\n","    print(\"Generate txt in ImageSets done.\")\n","\n","if annotation_mode == 0 or annotation_mode == 2:\n","    print(\"Generate 2007_train.txt and 2007_val.txt for train.\")\n","    for year, image_set in VOCdevkit_sets:\n","        image_ids = open(os.path.join(VOCdevkit_path, 'VOC%s/ImageSets/Main/%s.txt' % (year, image_set)),\n","                            encoding='utf-8').read().strip().split()\n","        list_file = open('./data/%s_%s.txt' % (year, image_set), 'w', encoding='utf-8')\n","        for image_id in image_ids:\n","            list_file.write('%s/VOC%s/JPEGImages/%s.jpg' % (os.path.abspath(VOCdevkit_path), year, image_id))\n","\n","            convert_annotation(year, image_id, list_file)\n","            list_file.write('\\n')\n","        list_file.close()\n","    print(\"Generate 2007_train.txt and 2007_val.txt for train done.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OnZ3mE6VOLwY","executionInfo":{"status":"ok","timestamp":1650296313338,"user_tz":240,"elapsed":9060,"user":{"displayName":"Jiayao Jin","userId":"06055959675371134357"}},"outputId":"a4c1d1dd-15b5-465f-c483-945761d1a546"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Generate txt in ImageSets.\n","train and val size 767\n","train size 690\n","Generate txt in ImageSets done.\n","Generate 2007_train.txt and 2007_val.txt for train.\n","Generate 2007_train.txt and 2007_val.txt for train done.\n"]}]}]}